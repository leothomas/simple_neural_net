{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from matrix_neural_net import Network\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TqdmUpdate(tqdm):\n",
    "     def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        \"\"\"\n",
    "        b  : int, optional\n",
    "            Number of blocks transferred so far [default: 1].\n",
    "        bsize  : int, optional\n",
    "            Size of each block (in tqdm units) [default: 1].\n",
    "        tsize  : int, optional\n",
    "            Total size (in tqdm units). If [default: None] remains unchanged.\n",
    "        \"\"\"\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        \n",
    "        self.update(b * bsize - self.n)  # will also set self.n = b * bsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and labels of the MNIST data set \n",
    "# each element in x_train/x_test is a handwritten digit\n",
    "# and each element in y_train/y_test is the associated \n",
    "# label for that digit (0-9)\n",
    "if not os.path.exists('./data/mnist/X.npy'):\n",
    "    import mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    X = np.append(x_train, x_test)\n",
    "    y = np.append(y_train, y_test)\n",
    "    np.save('./data/mnist/X', X)\n",
    "    np.save('./data/mnist/y', y)\n",
    "\n",
    "X = np.load('./data/mnist/X.npy')\n",
    "X = X.reshape(70000, 28, 28)\n",
    "# divide by 255 to normalize values\n",
    "X = np.array([ (x.flatten())/255 for x in X])\n",
    "\n",
    "y = np.load('./data/mnist/y.npy')\n",
    "y = y.reshape(70000, )\n",
    "y = np.array([int(i) for i in y])\n",
    "\n",
    "# One hot encode the y data (target variable)\n",
    "temp = np.zeros((y.size, int(y.max())+1))\n",
    "temp[np.arange(y.size),y] = 1\n",
    "y = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa283d97290>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of one of the handwritten digits\n",
    "plt.imshow(X[432].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y[432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each image is 28x28 pixels, which is flattened\n",
    "# out into an input array of length 784\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate network with sigmoid activation\n",
    "# this shape returns an ~80% testing accuracy \n",
    "# and takes about 4m30s to train on the MNIST \n",
    "# dataset (60,000 images) on an intel pentium, \n",
    "# 8Gb memory\n",
    "network = Network(\n",
    "    shape=[784, 200, 80, 10], \n",
    "    activation = 'sigmoid', output_activation='sigmoid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96642771, 0.69700636, 0.8229515 , 0.04989764, 0.14217617,\n",
       "       0.96098167, 0.55232396, 0.98196917, 0.36432889, 0.82152129])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that the forwad pass works and provides an \n",
    "# output with a probability for each label\n",
    "guess = network.forward_pass(X[0])\n",
    "guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the position of the highest probability is taken\n",
    "# to be the network's output\n",
    "interpret = lambda x: np.argmax(x)\n",
    "interpret(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the backwards pass works\n",
    "network.backward_pass(\n",
    "    network_input = X[0],\n",
    "    network_output = guess, \n",
    "    expected_output = y[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 41712/56000 [06:25<02:15, 105.19it/s]"
     ]
    }
   ],
   "source": [
    "with TqdmUpdate() as t: \n",
    "    network.learning_rate = 0.01\n",
    "    training_accuracy, testing_accuracy = network.train_test(X, y, test_split=0.2, progress=t.update_to)\n",
    "    print (\"Train acc: %.4f - Test acc: %.4f\" %(training_accuracy, testing_accuracy))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [53:06<12:23:30, 1593.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8dbd6863f732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mTqdmUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtraining_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Train acc: %.4f - Test acc: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/simple_neural_net/matrix_neural_net.py\u001b[0m in \u001b[0;36mtrain_test_minibatch\u001b[0;34m(self, X, y, mode, learning_rate, test_split, batch_size, epochs, progress)\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mbp_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mback_prop_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                     \u001b[0mback_prop_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/simple_neural_net/matrix_neural_net.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(self, network_input, network_output, expected_output)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# error/ delta for the next layer of weights and biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transfer_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__activations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with TqdmUpdate() as t: \n",
    "    network.learning_rate = 0.5\n",
    "    training_accuracy, testing_accuracy = network.train_test_minibatch(X, y, test_split=0.2,epochs=30, progress=t.update_to)\n",
    "    print (\"Train acc: %.4f - Test acc: %.4f\" %(training_accuracy, testing_accuracy))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing accuracy: the percentage of correct guesses in \n",
    "# each testing pass\n",
    "plt.figure()\n",
    "plt.plot(accuracies)\n",
    "plt.title(\"Network Testing Accuracy\")\n",
    "plt.xlabel(\"Testing Epoch\")\n",
    "plt.ylabel(\"% of correct labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSSIBLE IMPROVEMENTS: \n",
    "# 1. Implement Softmax output activation function. I have read that this \n",
    "#    performs better with classification problems since it normalizes the \n",
    "#    the output vector to have a norm of 1\n",
    "# 3. Implement some sort of data set augmentation \n",
    "# 4. Implement some sort of convolution and pooling layers for faster computation\n",
    "# 5. Implement adams optimizer for more efficient gradient descent\n",
    "# 6. Research more on various error functions that can be used to evaluate the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
