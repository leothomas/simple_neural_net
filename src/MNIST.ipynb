{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from networks.matrix_neural_net import NeuralNetwork\n",
    "from network_manager import NetworkManager\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TqdmUpdate(tqdm):\n",
    "     def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        \"\"\"\n",
    "        b  : int, optional\n",
    "            Number of blocks transferred so far [default: 1].\n",
    "        bsize  : int, optional\n",
    "            Size of each block (in tqdm units) [default: 1].\n",
    "        tsize  : int, optional\n",
    "            Total size (in tqdm units). If [default: None] remains unchanged.\n",
    "        \"\"\"\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        \n",
    "        self.update(b * bsize - self.n)  # will also set self.n = b * bsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and labels of the MNIST data set \n",
    "# each element in x_train/x_test is a handwritten digit\n",
    "# and each element in y_train/y_test is the associated \n",
    "# label for that digit (0-9)\n",
    "if not os.path.exists('./data/mnist/X.npy'):\n",
    "    import mnist\n",
    "    x_train, y_train = mnist.train_images(), mnist.train_labels()\n",
    "    x_test, y_test = mnist.test_images(), mnist.test_labels()\n",
    "    X = np.append(x_train, x_test)\n",
    "    y = np.append(y_train, y_test)\n",
    "#     np.save('./data/mnist/X', X)\n",
    "#     np.save('./data/mnist/y', y)\n",
    "    \n",
    "# X = np.load('./data/mnist/X.npy')\n",
    "X = X.reshape(70000, 28, 28)\n",
    "# divide by 255 to normalize values\n",
    "X = np.array([ (x.flatten())/255 for x in X])\n",
    "\n",
    "# y = np.load('./data/mnist/y.npy')\n",
    "y = y.reshape(70000, )\n",
    "y = np.array([int(i) for i in y])\n",
    "\n",
    "# One hot encode the y data (target variable)\n",
    "temp = np.zeros((y.size, int(y.max())+1))\n",
    "temp[np.arange(y.size),y] = 1\n",
    "y = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[0:10000]\n",
    "X = X[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1172ad4c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of one of the handwritten digits\n",
    "plt.imshow(X[432].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y[432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each image is 28x28 pixels, which is flattened\n",
    "# out into an input array of length 784\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate network with sigmoid activation\n",
    "# this shape returns an ~96% testing accuracy \n",
    "# and takes about 9min to train on the MNIST \n",
    "# dataset (60,000 images) on an intel pentium, \n",
    "# 8Gb memory\n",
    "network = NeuralNetwork(\n",
    "    shape=[784, 200, 80, 10], \n",
    "    activation = 'tanh', output_activation='sigmoid',\n",
    "    loss=\"cross_entropy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06307648, 0.17140734, 0.11572089, 0.06307925, 0.12527176,\n",
       "       0.06311586, 0.06307638, 0.10072822, 0.17144746, 0.06307636])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that the forwad pass works and provides an \n",
    "# output with a probability for each label\n",
    "guess = network.forward_pass(X[0])\n",
    "guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the position of the highest probability is taken\n",
    "# to be the network's output\n",
    "interpret = lambda x: np.argmax(x)\n",
    "interpret(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the backwards pass works\n",
    "network.backward_pass(\n",
    "    network_input = X[0],\n",
    "    network_output = guess, \n",
    "    expected_output = y[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 13999/14000 [00:36<00:00, 384.56it/s]  \n"
     ]
    }
   ],
   "source": [
    "network_params = {\n",
    "    'shape': [784, 200, 40, 10],\n",
    "    'activation': 'sigmoid',\n",
    "    'output_activation': 'sigmoid',\n",
    "    'loss':'cross_entropy',\n",
    "    'learning_rate': 0.001\n",
    "}\n",
    "network = NeuralNetwork(**network_params)\n",
    "manager = NetworkManager(network)\n",
    "with TqdmUpdate() as t: \n",
    "    training, testing = manager.train_test(X, y, mode=\"classify\", progress=t.update_to)\n",
    "    #training, testing = manager.kfold(X, y,k=10, split=0.2, mode=\"classify\", progress=t.update_to)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9921208141825345,\n",
       "  0.6195121951219512,\n",
       "  0.8002735978112175,\n",
       "  0.7007930785868781,\n",
       "  0.10539018503620273,\n",
       "  0.844043321299639,\n",
       "  0.8647512263489839,\n",
       "  0.4001473839351511,\n",
       "  0.8018698309960446],\n",
       " 'recall': [0.5813774528664871,\n",
       "  0.8045248868778281,\n",
       "  0.6331168831168831,\n",
       "  0.8026424442609413,\n",
       "  0.903448275862069,\n",
       "  0.730625,\n",
       "  0.7389221556886227,\n",
       "  0.8165413533834587,\n",
       "  0.7063668039277795],\n",
       " 'accuracy': 0.7021428571428572,\n",
       " 'fscore': 0.7121940309709873}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSSIBLE IMPROVEMENTS: \n",
    "# 1. Implement Softmax output activation function. I have read that this \n",
    "#    performs better with classification problems since it normalizes the \n",
    "#    the output vector to have a norm of 1\n",
    "# 3. Implement some sort of data set augmentation \n",
    "# 4. Implement some sort of convolution and pooling layers for faster computation\n",
    "# 5. Implement adams optimizer for more efficient gradient descent\n",
    "# 6. Research more on various error functions that can be used to evaluate the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
